[WAIT_UNTIL]
# Default exceptions to be ignored during wait_until execution
default_exceptions = ["builtins.AssertionError", ]
# Default timeout in seconds
default_timeout = 10
# Default interval between retries in seconds
default_interval = 0.5

[TEST_CASE]
# Required properties for all test cases
required_properties = ["scope", "component"]
# Valid test scope values
valid_scopes = ["unit", "integration", "e2e", "system", "Backend", "123"]


[TEST_RUN]
test_owner = default_user
app_under_test = example_app
version = 0.0.1


[REPORT]
# Type of report to generate
# Available options:
#   one_pager - Single page report with all information
#   drilldown - Main page with links to detailed suite pages
type = one_pager

# Sections to include in the report
# Available sections (comma-separated):
#   main_summary - Overall test statistics
#   test_suite_summary - Statistics per test suite
#   test_case_summary - Detailed test case results
# Example: main_summary,test_results,test_case_summary
sections = main_summary,test_results,test_case_summary

# Custom columns to add to summary tables
# Format: List of column names in Python list syntax
# These columns will be populated from custom_metrics if available
# Example: ["comments", "jira_link", "author"]
custom_columns = ["comments"]

# Threshold for failed tests percentage to mark entire run as failed
# Range: 0-100
# Example: 90 means if more than 90% of tests failed, mark run as failed
failed_threshold = 100

# Columns to display in test case results
# Available columns (comma-separated list):
#   test_name - Name of the test
#   test_function - Name of the pytest function initiating the test
#   description - Test description
#   result - Test result (PASSED/FAILED/SKIPPED)
#   test_start - Test start time
#   test_end - Test end time
#   duration - Test duration in seconds
#   failure - Failure message if test failed
#   failure_type - Type of failure
#   steps - Test steps from test execution
#   custom_metrics - Custom metrics from test execution
# Example: test_name,description,result,duration,failure
columns = ["test_name", "test_function", "description", "result", "test_start", "duration", "failure", "failure_type", "custom_metrics", "steps"]


# Whether to include charts in the report
# If true, adds visual representations of test results
# Default: true
show_charts = true

# CSS template to use for styling
# Available templates:
#   modern     - Modern theme with shadows and vibrant colors
#   minimalist - Clean and simple design
#   dark       - Dark mode theme
#   retro      - Retro-inspired theme
#   classic    - A classic theme with a modern twist
# Default: modern
css_template = classic

# Filter options for test results
# Available filters (comma-separated):
#   status - Filter by test status (passed,failed,skipped)
#   suite - Filter by test suite name
#   component - Filter by component name
#   date_range - Filter by date range (format: YYYY-MM-DD:YYYY-MM-DD)
# Example: status=failed,suite=Authentication
filters = ""


[FRAMEWORK]
# Whether to drop database on initialization (useful for testing framework)
drop_database = true
# Default test owner
test_owner = kriz
# Default test environment
environment = dev


[PLAYWRIGHT]
browser_type=chromium
headless=false
window_size=maximized
# slow motion delay in milliseconds.
slow_mo=0
# default timeout for waiting for elements on UI
timeout=30
#retry interval for element wait operations
retry_interval=0.5
# whether to use strict tag matching
strict_tag_matching=False

